#!/usr/bin/env python3
"""
ä»æŒ‡å®šè·¯å¾„è¯»å–å¤šå¼ å›¾ç‰‡ç”Ÿæˆ3Dç»“æ„
"""
import os
import sys
import argparse
import time
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from triposg.pipelines.pipeline_triposg import TripoSGPipeline
import torch
import numpy as np
from PIL import Image
import trimesh

def resize_image(image, max_size=512):
    """è°ƒæ•´å›¾åƒå°ºå¯¸ä»¥ä¼˜åŒ–å†…å­˜ä½¿ç”¨"""
    width, height = image.size
    
    if max(width, height) > max_size:
        if width > height:
            new_width = max_size
            new_height = int(height * max_size / width)
        else:
            new_height = max_size
            new_width = int(width * max_size / height)
        
        print(f"è°ƒæ•´å›¾åƒå°ºå¯¸: {width}x{height} -> {new_width}x{new_height}")
        return image.resize((new_width, new_height), Image.Resampling.LANCZOS)
    
    return image

def create_multiview_fusion(image_paths, max_width=1024):
    """åˆ›å»ºå¤šè§†è§’èåˆå›¾åƒï¼ˆç½‘æ ¼å¸ƒå±€ï¼‰"""
    print("ğŸ–¼ï¸  åˆ›å»ºå¤šè§†è§’èåˆå›¾åƒ...")
    
    images = []
    for img_path in image_paths:
        if os.path.exists(img_path):
            img = Image.open(img_path).convert('RGB')
            img = resize_image(img, 256)
            images.append(img)
            print(f"âœ… åŠ è½½å›¾åƒ: {os.path.basename(img_path)}")
        else:
            print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {img_path}")
            return None
    
    if not images:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„å›¾åƒæ–‡ä»¶")
        return None
    
    # è®¡ç®—ç½‘æ ¼å¸ƒå±€
    num_images = len(images)
    if num_images <= 4:
        grid_cols = 2
        grid_rows = (num_images + 1) // 2
    else:
        grid_cols = 3
        grid_rows = (num_images + 2) // 3
    
    # è®¡ç®—æœ€ç»ˆå›¾åƒå°ºå¯¸
    img_width, img_height = images[0].size
    total_width = img_width * grid_cols
    total_height = img_height * grid_rows
    
    # å¦‚æœæ€»å°ºå¯¸è¿‡å¤§ï¼Œè¿›è¡Œç¼©æ”¾
    if total_width > max_width:
        scale_factor = max_width / total_width
        new_width = int(total_width * scale_factor)
        new_height = int(total_height * scale_factor)
        
        print(f"èåˆå›¾åƒå°ºå¯¸è¿‡å¤§ï¼Œè¿›è¡Œç¼©æ”¾: {total_width}x{total_height} -> {new_width}x{new_height}")
        
        # ç¼©æ”¾æ‰€æœ‰å›¾åƒ
        resized_images = []
        for img in images:
            new_img_width = int(img.width * scale_factor)
            new_img_height = int(img.height * scale_factor)
            resized_img = img.resize((new_img_width, new_img_height), Image.Resampling.LANCZOS)
            resized_images.append(resized_img)
        
        images = resized_images
        img_width, img_height = images[0].size
        total_width = img_width * grid_cols
        total_height = img_height * grid_rows
    
    # åˆ›å»ºç½‘æ ¼å¸ƒå±€çš„èåˆå›¾åƒ
    fused_image = Image.new('RGB', (total_width, total_height), color='white')
    
    # æŒ‰ç½‘æ ¼å¸ƒå±€ç²˜è´´å›¾åƒ
    for i, img in enumerate(images):
        row = i // grid_cols
        col = i % grid_cols
        x_offset = col * img_width
        y_offset = row * img_height
        fused_image.paste(img, (x_offset, y_offset))
    
    print(f"âœ… ç½‘æ ¼èåˆå›¾åƒå®Œæˆï¼Œå°ºå¯¸: {fused_image.size}ï¼Œå¸ƒå±€: {grid_rows}x{grid_cols}")
    return fused_image

def run_pipeline_optimized(pipe, image, device, params):
    """ä¼˜åŒ–çš„ç®¡é“è¿è¡Œå‡½æ•°"""
    pipe_params = {
        'image': image,
        'num_inference_steps': params['num_inference_steps'],
        'guidance_scale': params['guidance_scale'],
        'num_tokens': params['num_tokens'],
        'generator': torch.Generator(device=device).manual_seed(42)
    }
    
    if params.get('use_flash_decoder', True):
        pipe_params['use_flash_decoder'] = True
        pipe_params['flash_octree_depth'] = params.get('flash_octree_depth', 6)
    else:
        pipe_params['use_flash_decoder'] = False
        pipe_params['dense_octree_depth'] = params.get('dense_octree_depth', 6)
        pipe_params['hierarchical_octree_depth'] = params.get('hierarchical_octree_depth', 7)
    
    return pipe(**pipe_params)

def run_pipeline_with_timing(pipe, image, device, params):
    """å¸¦è®¡æ—¶åŠŸèƒ½çš„ç®¡é“è¿è¡Œå‡½æ•°"""
    start_time = time.time()
    result = run_pipeline_optimized(pipe, image, device, params)
    end_time = time.time()
    
    execution_time = end_time - start_time
    return result, execution_time

def save_optimized_result(result, filename):
    """ä¿å­˜ä¼˜åŒ–ç‰ˆç»“æœ"""
    if hasattr(result, 'meshes') and result.meshes:
        mesh = result.meshes[0]
    else:
        mesh = trimesh.Trimesh(result.samples[0][0].astype(np.float32), 
                              np.ascontiguousarray(result.samples[0][1]))
    
    mesh.export(filename)
    print(f"âœ… ç½‘æ ¼å·²ä¿å­˜: {filename}")
    print(f"  é¡¶ç‚¹æ•°: {len(mesh.vertices)}")
    print(f"  é¢æ•°: {len(mesh.faces)}")
    return mesh

def generate_3d_from_images(image_paths, output_file="multiview_output.glb"):
    """ä»å›¾åƒè·¯å¾„åˆ—è¡¨ç”Ÿæˆ3Dç»“æ„"""
    print("ğŸš€ åˆå§‹åŒ–3Dç”Ÿæˆå™¨...")
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    try:
        pipe = TripoSGPipeline.from_pretrained(
            "pretrained_weights/TripoSG"
        ).to(device)
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    # æ£€æŸ¥å›¾åƒæ–‡ä»¶å­˜åœ¨æ€§
    valid_paths = []
    for img_path in image_paths:
        if os.path.exists(img_path):
            valid_paths.append(img_path)
        else:
            print(f"âš ï¸  å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {img_path}")
    
    if not valid_paths:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„å›¾åƒæ–‡ä»¶")
        return
    
    print(f"âœ… ä½¿ç”¨ {len(valid_paths)} ä¸ªè§†è§’ç”Ÿæˆ3Dæ¨¡å‹...")
    
    try:
        # åˆ›å»ºå¤šè§†è§’èåˆå›¾åƒ
        fused_image = create_multiview_fusion(valid_paths, max_width=512)
        if fused_image is None:
            return
        
        # ä¿å­˜èåˆå›¾åƒç”¨äºè°ƒè¯•
        fused_image.save("multiview_fused_current.jpg")
        print("âœ… å¤šè§†è§’å›¾åƒèåˆå®Œæˆ")
        
        # ä½¿ç”¨ä¼˜åŒ–å‚æ•°
        params = {
            'num_inference_steps': 25,
            'guidance_scale': 7.0,
            'num_tokens': 1024,
            'use_flash_decoder': True,
            'flash_octree_depth': 6,
        }
        
        result, execution_time = run_pipeline_with_timing(pipe, fused_image, device, params)
        
        print(f"âœ… æ¨ç†å®Œæˆï¼è€—æ—¶: {execution_time:.2f}ç§’")
        
        # ä¿å­˜ç»“æœ
        save_optimized_result(result, output_file)
        print(f"ğŸ¯ 3Dç”Ÿæˆå®Œæˆï¼ç»“æœä¿å­˜åˆ°: {output_file}")
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ä»æŒ‡å®šè·¯å¾„è¯»å–å›¾ç‰‡ç”Ÿæˆ3Dç»“æ„')
    parser.add_argument('--image-dir', help='åŒ…å«å¤šè§†è§’å›¾åƒçš„ç›®å½•è·¯å¾„')
    parser.add_argument('--image-paths', nargs='+', help='æŒ‡å®šå›¾åƒæ–‡ä»¶è·¯å¾„åˆ—è¡¨')
    parser.add_argument('--output', default='multiview_output.glb',
                       help='è¾“å‡º3Dæ¨¡å‹æ–‡ä»¶åï¼ˆé»˜è®¤ï¼šmultiview_output.glbï¼‰')
    
    args = parser.parse_args()
    
    # è·å–å›¾åƒè·¯å¾„åˆ—è¡¨
    image_paths = []
    
    if args.image_paths:
        # ä½¿ç”¨æŒ‡å®šçš„å›¾åƒè·¯å¾„åˆ—è¡¨
        image_paths = args.image_paths
        print(f"ğŸ“‹ ä½¿ç”¨æŒ‡å®šçš„å›¾åƒåˆ—è¡¨: {len(image_paths)} ä¸ªæ–‡ä»¶")
        
    elif args.image_dir:
        # ä»ç›®å½•ä¸­è¯»å–æ‰€æœ‰PNGå’ŒJPGå›¾åƒ
        if os.path.exists(args.image_dir):
            for filename in os.listdir(args.image_dir):
                if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(args.image_dir, filename))
            print(f"ğŸ“ ä»ç›®å½•è¯»å–å›¾åƒ: {len(image_paths)} ä¸ªæ–‡ä»¶")
        else:
            print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {args.image_dir}")
            return
    else:
        print("âŒ è¯·æŒ‡å®š --image-dir æˆ– --image-paths å‚æ•°")
        return
    
    if not image_paths:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å›¾åƒæ–‡ä»¶")
        return
    
    # ç”Ÿæˆ3Dç»“æ„
    generate_3d_from_images(image_paths, args.output)

if __name__ == "__main__":
    main()